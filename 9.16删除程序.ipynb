{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ad25b6-f2d9-4134-9eda-7bef064c3aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "import pathlib\n",
    "import math\n",
    "import numpy as np\n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3be85b9-d2c0-4089-b97a-8edab8755322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "API_BASE_URL = 'http://fireeye-test-backend-container:9090/api/'\n",
    "TF_SERVING_BASE_URL = 'http://fireeye-test-model-container:8501/'\n",
    "task_id = '1ac1e8a095df4611af387d9934799251'\n",
    "id_code_mapping = {\n",
    "    'dbee3deebc5444f5b011da4e5518752c': '0',\n",
    "    'edb4cb51d54644c08aa122d3f041bb0a': '1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76012b3c-737d-4c1d-aa89-9ce2bc2387d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_by_id(image_id):\n",
    "    \"\"\"Retrieve image by its ID.\"\"\"\n",
    "    r = requests.get(url=API_BASE_URL + 'image/' + image_id)\n",
    "    if r.status_code == 200:\n",
    "        return Image.open(io.BytesIO(r.content))\n",
    "    else:\n",
    "        raise RuntimeError(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "815320be-3292-4d22-99a6-1a2a4ea21dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该类别下图片数量是：320\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "def get_image_records(task_id):\n",
    "    \"\"\"Fetch image records given a task ID.\"\"\"\n",
    "    resp = requests.get(\n",
    "        url=API_BASE_URL + 'image',\n",
    "        params={'task_id': task_id, 'has_truth': True}\n",
    "    )\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        raise RuntimeError(resp.text)\n",
    "image_records = get_image_records(task_id)\n",
    "print(f'该类别下图片数量是：{len(image_records)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b0c0ae-0a27-40a3-a0ae-cc4415576cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crop_by_percentile(img, lower_percentile=5, upper_percentile=95):\n",
    "    img_array = np.array(img.convert('L'))\n",
    "    \n",
    "    low_val, high_val = np.percentile(img_array, [lower_percentile,upper_percentile])\n",
    "                         \n",
    "    mask = np.logical_and(img_array > low_val, img_array < high_val)\n",
    "    rows = np.any(mask, axis=1)\n",
    "    cols = np.any(mask, axis=0)\n",
    "                         \n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    cropped_img = img.crop((cmin, rmin, cmax, rmax))\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c845b9a9-6bcc-4e30-a9ef-e4dccaae5f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image(img: Image.Image) -> np.ndarray:\n",
    "    img_array = np.array(img)\n",
    "    return img_array / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3d05648-952f-4c26-a4d9-8208438777d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_dir = \"./images\"\n",
    "Category0_dir = os.path.join(image_dir, 'Category0')\n",
    "Category1_dir = os.path.join(image_dir, 'Category1')\n",
    "if os.path.exists(Category0_dir):\n",
    "    shutil.rmtree(Category0_dir)\n",
    "if os.path.exists(Category1_dir):\n",
    "    shutil.rmtree(Category1_dir)\n",
    "\n",
    "\n",
    "os.makedirs(Category0_dir)\n",
    "os.makedirs(Category1_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca9430cc-693c-46cf-9266-2e75f30899c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clear_and_create_directory(directory):\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    os.makedirs(directory)\n",
    "\n",
    "base_dir = './images'\n",
    "\n",
    "for set_name in ['train', 'test', 'val']:\n",
    "    for category in ['Category0', 'Category1']:\n",
    "        directory = os.path.join(base_dir, set_name, category)\n",
    "        clear_and_create_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb9eca4-2400-4c2d-ad85-82bbe86450f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [id_code_mapping[record['truth_id']] for record in image_records]\n",
    "\n",
    "\n",
    "train_records, test_records, train_labels, test_labels = train_test_split(\n",
    "    image_records, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "train_records, val_records, train_labels, val_labels = train_test_split(\n",
    "    train_records, train_labels, test_size=0.1, stratify=train_labels, random_state=42)\n",
    "\n",
    "\n",
    "# Saving images for Test and Validation Sets without processing\n",
    "for set_name, records in [('train', train_records), ('test', test_records), ('val', val_records)]:\n",
    "    for record in records:\n",
    "        try:\n",
    "            img = get_image_by_id(record['id'])\n",
    "            cropped_img = crop_by_percentile(img)\n",
    "            normalized_img_array = np.array(cropped_img) / 255.0\n",
    "            normalized_img = Image.fromarray((normalized_img_array * 255).astype(np.uint8))\n",
    "\n",
    "            truth_id = record['truth_id']\n",
    "            category = id_code_mapping[truth_id]\n",
    "\n",
    "            directory = os.path.join(base_dir, set_name, f'Category{category}')\n",
    "            file_path = os.path.join(directory, f'{record[\"id\"]}.png')\n",
    "            normalized_img.save(file_path, 'PNG')\n",
    "        except Exception as e:\n",
    "           print(f'Error processing image {record[\"id\"]}. Error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63eaeddc-6cb4-43cf-929b-6b2e6eb7dfc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_image(image_id):\n",
    "    response = requests.get(f\"{API_BASE_URL}image/download/{image_id}\")\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "620373ff-f17f-4f80-9b27-071677d3a5f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def color_jitter(img: Image.Image, brightness=0.2, contrast=0.2, saturation=0.2) -> Image.Image:\n",
    "    img = ImageEnhance.Brightness(img).enhance(1 + brightness * (2 * np.random.random() - 1))\n",
    "    img = ImageEnhance.Contrast(img).enhance(1 + contrast * (2 * np.random.random() - 1))\n",
    "    img = ImageEnhance.Color(img).enhance(1 + saturation * (2 * np.random.random() - 1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d55601c5-7dab-4c51-8705-d1b8754423bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vertical_flip(img: Image.Image) -> Image.Image:\n",
    "    return ImageOps.flip(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f45fa63d-790e-4a4d-8957-38d0ee14f1ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def horizontal_flip(img: Image.Image) -> Image.Image:\n",
    "    return ImageOps.mirror(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d66fee42-d32f-4e2d-bbfd-a5315c458077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation for the training set is complete\n"
     ]
    }
   ],
   "source": [
    "train_directory = './images/train/'\n",
    "\n",
    "\n",
    "def preprocess_and_save(img_path, image_id, category):\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    color_jittered = color_jitter(img)\n",
    "    color_jittered_path = os.path.join(train_directory, category, f'{image_id}_colorjittered.png')\n",
    "    color_jittered.save(color_jittered_path, 'PNG')\n",
    "\n",
    "    vflipped = vertical_flip(img)\n",
    "    vflipped_path = os.path.join(train_directory, category, f'{image_id}_vflipped.png')\n",
    "    vflipped.save(vflipped_path, 'PNG')\n",
    "\n",
    "    hflipped = horizontal_flip(img)\n",
    "    hflipped_path = os.path.join(train_directory, category, f'{image_id}_hflipped.png')\n",
    "    hflipped.save(hflipped_path, 'PNG')\n",
    "#    img = get_image_by_id(image_id)\n",
    "for record in train_records:\n",
    "    image_id = record['id']\n",
    "    truth_id = record['truth_id']\n",
    "    category = f'Category{id_code_mapping[truth_id]}'\n",
    "    img_path = os.path.join(train_directory, category, f'{image_id}.png')\n",
    "    if os.path.exists(img_path):\n",
    "        preprocess_and_save(img_path, image_id, category)\n",
    "print('Data augmentation for the training set is complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db4235c-440d-4ae4-9f34-dce7ee59dd05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(tf.__version__)\n",
    "\n",
    "# Data directories\n",
    "train_dir = './images/train'\n",
    "val_dir = './images/val'\n",
    "test_dir = './images/test'\n",
    "\n",
    "# Image dimensions\n",
    "img_height, img_width = 218, 175\n",
    "input_shape = (img_height, img_width, 3)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a361d1cd-a0f6-499a-977c-e96b4b39d872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dataset(data_dir, target=None):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    for i in range(2):\n",
    "        if target is not None and i != target:\n",
    "            continue\n",
    "        images = glob.glob(os.path.join(data_dir, f'Category{i}/*.png'), recursive=True)\n",
    "        all_images.extend(images)\n",
    "        all_labels.extend([i] * len(images))\n",
    "    ds = tf.data.Dataset.from_tensor_slices((all_images, all_labels))\n",
    "    ds = ds.map(lambda x,y: (tf.io.encode_base64(tf.io.read_file(x)) ,y))\n",
    "    ds = ds.shuffle(100, seed=123)\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bcbe223-bedb-4bfa-8979-6a4f3977b99f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 804 images belonging to 2 classes.\n",
      "Found 23 images belonging to 2 classes.\n",
      "Found 96 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "val_image_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "test_image_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(img_height, img_width),\n",
    "                                                           class_mode='binary')\n",
    "\n",
    "val_data_gen = val_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                       directory=val_dir,\n",
    "                                                       target_size=(img_height, img_width),\n",
    "                                                       class_mode='binary')\n",
    "\n",
    "test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                         directory=test_dir,\n",
    "                                                         target_size=(img_height, img_width),\n",
    "                                                         class_mode='binary')\n",
    "\n",
    "\n",
    "def process_base64_image(s):\n",
    "    img = tf.io.decode_base64(s)\n",
    "    img = tf.io.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img, (img_height, img_width), antialias=True)    \n",
    "    return img / 255.0\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "\n",
    "    # CNN Layers\n",
    "    layers.Conv2D(16, 3, padding='same', activation='gelu', input_shape=(img_height, img_width, 3)),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(32, 3, padding='same', activation='gelu'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(64, 3, padding='same', activation='gelu'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    # Dense Layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='gelu', name=\"dense_layer1\"),\n",
    "\n",
    "    layers.Dense(1, activation='sigmoid', name=\"output_layer\")\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d2c8f83-b503-4709-b116-2786f0c2063b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 11s 380ms/step - loss: 0.4814 - accuracy: 0.7948 - val_loss: 0.2243 - val_accuracy: 0.8696\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 10s 378ms/step - loss: 0.1730 - accuracy: 0.9266 - val_loss: 0.0608 - val_accuracy: 0.9565\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 10s 387ms/step - loss: 0.0893 - accuracy: 0.9714 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 10s 385ms/step - loss: 0.0747 - accuracy: 0.9764 - val_loss: 0.0462 - val_accuracy: 0.9565\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 10s 378ms/step - loss: 0.0505 - accuracy: 0.9838 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 10s 383ms/step - loss: 0.0195 - accuracy: 0.9963 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 10s 380ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 10s 386ms/step - loss: 0.0399 - accuracy: 0.9838 - val_loss: 0.0337 - val_accuracy: 0.9565\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 10s 377ms/step - loss: 0.0290 - accuracy: 0.9925 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 10s 383ms/step - loss: 0.0063 - accuracy: 0.9963 - val_loss: 9.7058e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 10s 378ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 10s 377ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9565\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 10s 384ms/step - loss: 7.2712e-04 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 10s 379ms/step - loss: 6.3849e-04 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 10s 383ms/step - loss: 5.8425e-04 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 10s 388ms/step - loss: 4.7060e-04 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 10s 388ms/step - loss: 4.2753e-04 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 10s 387ms/step - loss: 3.9947e-04 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 10s 386ms/step - loss: 3.4221e-04 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 10s 382ms/step - loss: 3.4783e-04 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data_gen, epochs=20, validation_data=val_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c10a3b8f-266b-4a53-905a-07f86236b2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 5s 178ms/step - loss: 2.9406e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0002940577978733927, 1.0]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e78a4d78-3b89-4d99-882e-49e6d6ac01d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /models/slot1/20230916095124/assets\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "model_version =  datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y%m%d%H%M%S')\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    f'/models/slot1/{model_version}/',\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3dbff37c-105c-41a6-ae7f-b89c88d70c70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import base64\n",
    "#from typing import List\n",
    "\n",
    "\n",
    "#def image_to_tf_format(img: Image.Image) -> List[List[List[float]]]:\n",
    "#    img = img.resize((218, 175)).convert('RGB')\n",
    "#    img_array = np.array(img)\n",
    "#    img_array = img_array / 255.0\n",
    "#    return img_array.tolist()\n",
    "    \n",
    "\n",
    "\n",
    "#def predict_image(images: List[Image.Image]):\n",
    "#    data = [image_to_tf_format(img) for img in images]\n",
    "\n",
    "#    json_data ={\n",
    "#      'signature_name': 'serving_default',\n",
    "#      'instances': data\n",
    "#    }\n",
    "#    response = requests.post(url=TF_SERVING_BASE_URL+f'v1/models/slot1/versions/{model_version}:predict', # 根据部署地址填写\n",
    "#                             json=json_data,\n",
    "#                             headers={\"content-type\": \"application/json\"})\n",
    "#    if response.status_code != 200:\n",
    "#        raise RuntimeError('Request tf-serving failed: ' + response.text)\n",
    "#    resp_data = json.loads(response.text)    \n",
    "#    if 'predictions' not in resp_data:\n",
    "#        print(f'Unexpected response form TensorFlow Serving: {resp_data}')\n",
    "#        raise RuntimeError('Invalid response from TensorFlow Serving')\n",
    "#    return resp_data['predictions']\n",
    "\n",
    "\n",
    "#def test_image_model(test_dir, code, batch_size=10):    \n",
    "#    image_paths = list(pathlib.Path(test_dir).joinpath(str(code)).glob('./*.png')) \n",
    "    \n",
    "#    images = [Image.open(img_path) for img_path in image_paths]\n",
    "#    codes = []\n",
    " #   for step in range(math.ceil(len(images)/batch_size)):\n",
    " #       outputs = predict_image(images[step*batch_size:(step+1)*batch_size])\n",
    " #       for i, o in zip(image_paths, outputs):            \n",
    " #           if o != code:\n",
    " #               print('错误图片：', i)\n",
    " #       codes.extend(outputs)\n",
    " #   accuracy = round(codes.count(code) / len(codes), 4)\n",
    " #   return accuracy, codes\n",
    "\n",
    "#accuracy, codes = test_image_model(val_dir, 0)\n",
    "#print('类别0的准确率', accuracy)\n",
    "#print('类别0的测试结果', codes)\n",
    "#accuracy, codes = test_image_model(val_dir, 1)\n",
    "#print('类别1的准确率', accuracy)\n",
    "#print('类别1的测试结果', codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f28be234-18e4-46c1-b07e-d3c05774b6f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12185/3323936971.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_image_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'类别0的准确率'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'类别0的测试结果'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12185/3323936971.py\u001b[0m in \u001b[0;36mtest_image_model\u001b[0;34m(test_dir, code, batch_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'错误图片：'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "def predict_image(images):\n",
    "    bimages = []\n",
    "    for image in images:\n",
    "        with open(image, 'rb') as  fimage:\n",
    "            content = fimage.read()\n",
    "        bimage = base64.urlsafe_b64encode(content).decode()\n",
    "        bimages.append(bimage)\n",
    "    req_data ={\n",
    "      'inputs': bimages,\n",
    "    }\n",
    "    response = requests.post(TF_SERVING_BASE_URL+f'v1/models/slot1/versions/{model_version}:predict', # 根据部署地址填写\n",
    "                             json=req_data,\n",
    "                             headers={\"content-type\": \"application/json\"})\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError('Request tf-serving failed: ' + response.text)\n",
    "    resp_data = json.loads(response.text)    \n",
    "    if 'outputs' not in resp_data \\\n",
    "                        or type(resp_data['outputs']) is not list:\n",
    "        raise ValueError('Malformed tf-serving response')\n",
    "    outputs = np.argmax(resp_data['outputs'], axis=1).tolist()\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def test_image_model(test_dir, code, batch_size=10):    \n",
    "    images = list(pathlib.Path(test_dir, 'Category0').joinpath(str(code)).glob('./*.png')) \n",
    "    codes = []\n",
    "    for step in range(math.ceil(len(images)/batch_size)):\n",
    "        outputs = predict_image(images[step*batch_size:(step+1)*batch_size])\n",
    "        for i, o in zip(images, outputs):            \n",
    "            if o != code:\n",
    "                print('错误图片：', i)\n",
    "        codes.extend(outputs)\n",
    "    accuracy = round(codes.count(code) / len(codes), 4)\n",
    "    return accuracy, codes\n",
    "\n",
    "accuracy, codes = test_image_model(test_dir, 0)\n",
    "print('类别0的准确率', accuracy)\n",
    "print('类别0的测试结果', codes)\n",
    "accuracy, codes = test_image_model(test_dir, 1)\n",
    "print('类别1的准确率', accuracy)\n",
    "print('类别1的测试结果', codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9af4d-a40a-4507-a224-422b1e910483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
