{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ad25b6-f2d9-4134-9eda-7bef064c3aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "import pathlib\n",
    "import math\n",
    "import numpy as np\n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3be85b9-d2c0-4089-b97a-8edab8755322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "API_BASE_URL = 'http://fireeye-test-backend-container:9090/api/'\n",
    "TF_SERVING_BASE_URL = 'http://fireeye-test-model-container:8501/'\n",
    "task_id = '1ac1e8a095df4611af387d9934799251'\n",
    "id_code_mapping = {\n",
    "    'dbee3deebc5444f5b011da4e5518752c': '0',\n",
    "    'edb4cb51d54644c08aa122d3f041bb0a': '1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76012b3c-737d-4c1d-aa89-9ce2bc2387d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_by_id(image_id):\n",
    "    \"\"\"Retrieve image by its ID.\"\"\"\n",
    "    r = requests.get(url=API_BASE_URL + 'image/' + image_id)\n",
    "    if r.status_code == 200:\n",
    "        return Image.open(io.BytesIO(r.content))\n",
    "    else:\n",
    "        raise RuntimeError(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "815320be-3292-4d22-99a6-1a2a4ea21dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该类别下图片数量是：320\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "def get_image_records(task_id):\n",
    "    \"\"\"Fetch image records given a task ID.\"\"\"\n",
    "    resp = requests.get(\n",
    "        url=API_BASE_URL + 'image',\n",
    "        params={'task_id': task_id, 'has_truth': True}\n",
    "    )\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        raise RuntimeError(resp.text)\n",
    "image_records = get_image_records(task_id)\n",
    "print(f'该类别下图片数量是：{len(image_records)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b0c0ae-0a27-40a3-a0ae-cc4415576cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crop_by_percentile(img, lower_percentile=5, upper_percentile=95):\n",
    "    img_array = np.array(img.convert('L'))\n",
    "    \n",
    "    low_val, high_val = np.percentile(img_array, [lower_percentile,upper_percentile])\n",
    "                         \n",
    "    mask = np.logical_and(img_array > low_val, img_array < high_val)\n",
    "    rows = np.any(mask, axis=1)\n",
    "    cols = np.any(mask, axis=0)\n",
    "                         \n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    cropped_img = img.crop((cmin, rmin, cmax, rmax))\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c845b9a9-6bcc-4e30-a9ef-e4dccaae5f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image(img: Image.Image) -> np.ndarray:\n",
    "    img_array = np.array(img)\n",
    "    return img_array / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3d05648-952f-4c26-a4d9-8208438777d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_dir = \"./images\"\n",
    "Category0_dir = os.path.join(image_dir, 'Category0')\n",
    "Category1_dir = os.path.join(image_dir, 'Category1')\n",
    "if os.path.exists(Category0_dir):\n",
    "    shutil.rmtree(Category0_dir)\n",
    "if os.path.exists(Category1_dir):\n",
    "    shutil.rmtree(Category1_dir)\n",
    "\n",
    "\n",
    "os.makedirs(Category0_dir)\n",
    "os.makedirs(Category1_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca9430cc-693c-46cf-9266-2e75f30899c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clear_and_create_directory(directory):\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    os.makedirs(directory)\n",
    "\n",
    "base_dir = './images'    \n",
    "\n",
    "for set_name in ['train', 'test', 'val']:\n",
    "    for category in ['Category0', 'Category1']:\n",
    "        directory = os.path.join(base_dir, set_name, category)\n",
    "        clear_and_create_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb9eca4-2400-4c2d-ad85-82bbe86450f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [id_code_mapping[record['truth_id']] for record in image_records]\n",
    "\n",
    "\n",
    "train_records, test_records, train_labels, test_labels = train_test_split(\n",
    "    image_records, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "train_records, val_records, train_labels, val_labels = train_test_split(\n",
    "    train_records, train_labels, test_size=0.1, stratify=train_labels, random_state=42)\n",
    "\n",
    "\n",
    "for set_name, records in [('train', train_records), ('test', test_records), ('val', val_records)]:\n",
    "    for record in records:\n",
    "        try:\n",
    "            img = get_image_by_id(record['id'])\n",
    "            cropped_img = crop_by_percentile(img)\n",
    "            normalized_img_array = np.array(cropped_img) / 255.0\n",
    "            normalized_img = Image.fromarray((normalized_img_array * 255).astype(np.uint8))\n",
    "\n",
    "            truth_id = record['truth_id']\n",
    "            category = id_code_mapping[truth_id]\n",
    "            \n",
    "            directory = os.path.join(base_dir, set_name, f'Category{category}')\n",
    "            file_path = os.path.join(directory, f'{record[\"id\"]}.png')\n",
    "            normalized_img.save(file_path, 'PNG')\n",
    "        except Exception as e:\n",
    "            print(f'Error processing image {record[\"id\"]}. Error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63eaeddc-6cb4-43cf-929b-6b2e6eb7dfc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_image(image_id):\n",
    "    response = requests.get(f\"{API_BASE_URL}image/download/{image_id}\")\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "620373ff-f17f-4f80-9b27-071677d3a5f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def color_jitter(img: Image.Image, brightness=0.2, contrast=0.2, saturation=0.2) -> Image.Image:\n",
    "    img = ImageEnhance.Brightness(img).enhance(1 + brightness * (2 * np.random.random() - 1))\n",
    "    img = ImageEnhance.Contrast(img).enhance(1 + contrast * (2 * np.random.random() - 1))\n",
    "    img = ImageEnhance.Color(img).enhance(1 + saturation * (2 * np.random.random() - 1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d55601c5-7dab-4c51-8705-d1b8754423bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vertical_flip(img: Image.Image) -> Image.Image:\n",
    "    return ImageOps.flip(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f45fa63d-790e-4a4d-8957-38d0ee14f1ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def horizontal_flip(img: Image.Image) -> Image.Image:\n",
    "    return ImageOps.mirror(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d66fee42-d32f-4e2d-bbfd-a5315c458077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation for teh training set is complete.\n"
     ]
    }
   ],
   "source": [
    "train_directory = './images/train/'\n",
    "\n",
    "\n",
    "def preprocess_and_save(img, image_id, category):\n",
    "    color_jittered = color_jitter(img)\n",
    "    color_jittered_path = os.path.join(train_directory, category, f'{image_id}_colorjittered.png')\n",
    "    color_jittered.save(color_jittered_path, 'PNG')\n",
    "\n",
    "    vflipped = vertical_flip(img)\n",
    "    vflipped_path = os.path.join(train_directory, category, f'{image_id}_vflipped.png')\n",
    "    vflipped.save(vflipped_path, 'PNG')\n",
    "\n",
    "    hflipped = horizontal_flip(img)\n",
    "    hflipped_path = os.path.join(train_directory, category, f'{image_id}_hflipped.png')\n",
    "    hflipped.save(hflipped_path, 'PNG')\n",
    "\n",
    "for record in train_records:\n",
    "    image_id = record['id']\n",
    "    img = get_image_by_id(image_id)\n",
    "    truth_id = record['truth_id']\n",
    "    category = f'Category{id_code_mapping[truth_id]}'\n",
    "    preprocess_and_save(img, image_id, category)\n",
    "    \n",
    "print('Data augmentation for teh training set is complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db4235c-440d-4ae4-9f34-dce7ee59dd05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "print(tf.__version__)\n",
    "train_dir = './images/train'\n",
    "val_dir = './images/val'\n",
    "test_dir = './images/test'\n",
    "\n",
    "img_height, img_width = 218, 175\n",
    "input_shape = (img_height, img_width, 3)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bcbe223-bedb-4bfa-8979-6a4f3977b99f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 804 images belonging to 2 classes.\n",
      "Found 23 images belonging to 2 classes.\n",
      "Found 96 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-13 00:34:59.204206: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-09-13 00:34:59.204236: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-09-13 00:34:59.204250: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (58c881efe57c): /proc/driver/nvidia/version does not exist\n",
      "2023-09-13 00:34:59.204383: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation and normalization for training\n",
    "train_image_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Just rescaling for validation and test\n",
    "val_image_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "test_image_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Data Loading\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(img_height, img_width),\n",
    "                                                           class_mode='binary')\n",
    "\n",
    "val_data_gen = val_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                       directory=val_dir,\n",
    "                                                       target_size=(img_height, img_width),\n",
    "                                                       class_mode='binary')\n",
    "\n",
    "test_data_gen = test_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                         directory=test_dir,\n",
    "                                                         target_size=(img_height, img_width),\n",
    "                                                         class_mode='binary')\n",
    "\n",
    "\n",
    "# 2. Model Creation and Compilation\n",
    "\n",
    "def create_advanced_cnn(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_advanced_cnn(input_shape)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d2c8f83-b503-4709-b116-2786f0c2063b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 13s 510ms/step - loss: 0.7683 - accuracy: 0.7137\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 13s 503ms/step - loss: 0.2489 - accuracy: 0.9050\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 12s 486ms/step - loss: 0.1317 - accuracy: 0.9585\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 12s 477ms/step - loss: 0.1858 - accuracy: 0.9352\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 12s 492ms/step - loss: 0.2036 - accuracy: 0.9337\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 12s 477ms/step - loss: 0.1197 - accuracy: 0.9611\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 12s 476ms/step - loss: 0.0600 - accuracy: 0.9767\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 12s 478ms/step - loss: 0.0491 - accuracy: 0.9883\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 12s 477ms/step - loss: 0.0234 - accuracy: 0.9961\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 12s 474ms/step - loss: 0.0190 - accuracy: 0.9961\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 12s 478ms/step - loss: 0.0160 - accuracy: 0.9948\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 12s 476ms/step - loss: 0.0140 - accuracy: 0.9974\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 12s 480ms/step - loss: 0.0170 - accuracy: 0.9961\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 12s 480ms/step - loss: 0.0935 - accuracy: 0.9676\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 12s 482ms/step - loss: 0.0254 - accuracy: 0.9961\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 12s 479ms/step - loss: 0.0052 - accuracy: 0.9987\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 12s 482ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 12s 490ms/step - loss: 0.0095 - accuracy: 0.9974\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 12s 483ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 12s 484ms/step - loss: 0.0030 - accuracy: 0.9987\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=train_data_gen.samples // BATCH_SIZE,\n",
    "    epochs=20,  # Adjust as needed\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=val_data_gen.samples // BATCH_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c10a3b8f-266b-4a53-905a-07f86236b2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 196ms/step - loss: 0.0202 - accuracy: 0.9896\n",
      "Test accuracy: 0.9895833134651184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-13 00:39:06.438268: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/my_model/assets\n",
      "Model saved to ./saved_model/my_model\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data_gen)\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "model_path = \"./saved_model/my_model\"\n",
    "model.save(model_path)\n",
    "print(\"Model saved to\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e78a4d78-3b89-4d99-882e-49e6d6ac01d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /models/slot1/20230913083907/assets\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "model_version = datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y%m%d%H%M%S')\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    f'/models/slot1/{model_version}/',\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59a1ca0a-0c04-40f7-a05d-8b1e9a1205c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No predictions found for category 0.\n",
      "类别0的准确率: 0.0\n",
      "类别0的测试结果: []\n",
      "No predictions found for category 1.\n",
      "类别1的准确率: 0.0\n",
      "类别1的测试结果: []\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "def predict_image(images):\n",
    "    bimages = []\n",
    "    for image in images:\n",
    "        with open(image, 'rb') as  fimage:\n",
    "            content = fimage.read()\n",
    "        bimage = base64.urlsafe_b64encode(content).decode()\n",
    "        bimages.append(bimage)\n",
    "    req_data ={\n",
    "      'inputs': bimages,\n",
    "    }\n",
    "    response = requests.post(TF_SERVING_BASE_URL+f'v1/models/slot1/versions/{model_version}:predict', # 根据部署地址填写\n",
    "                             json=req_data,\n",
    "                             headers={\"content-type\": \"application/json\"})\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError('Request tf-serving failed: ' + response.text)\n",
    "    resp_data = json.loads(response.text)\n",
    "    if 'outputs' not in resp_data \\\n",
    "                        or type(resp_data['outputs']) is not list:\n",
    "        raise ValueError('Malformed tf-serving response')\n",
    "    outputs = np.argmax(resp_data['outputs'], axis=1).tolist()\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def test_image_model(test_dir, code, batch_size=10):\n",
    "    # Points to the specific category directory in test_dir\n",
    "    category_dir = pathlib.Path(test_dir).joinpath(str(code))\n",
    "\n",
    "    # Glob finds all the pathnames matching the specified pattern\n",
    "    images = list(category_dir.glob('./*.png'))\n",
    "\n",
    "    codes = []\n",
    "    for step in range(math.ceil(len(images) / batch_size)):\n",
    "        batch_images = images[step * batch_size:(step + 1) * batch_size]\n",
    "        if not batch_images:  # If the list is empty, skip\n",
    "            continue\n",
    "        outputs = predict_image(batch_images)\n",
    "\n",
    "        # If no outputs are returned, it could mean an issue in predict_image function\n",
    "        if not outputs:\n",
    "            print(f\"No outputs for batch {step}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        for i, o in zip(batch_images, outputs):\n",
    "            if o != code:\n",
    "                print('Error picture:', i)\n",
    "        codes.extend(outputs)\n",
    "\n",
    "    # Check for zero-length to avoid ZeroDivisionError\n",
    "    if len(codes) == 0:\n",
    "        print(f\"No predictions found for category {code}.\")\n",
    "        accuracy = 0.0\n",
    "    else:\n",
    "        accuracy = round(codes.count(code) / len(codes), 4)\n",
    "\n",
    "    return accuracy, codes\n",
    "\n",
    "\n",
    "# Assuming test_dir = './images/test'\n",
    "test_dir = './images/test'\n",
    "\n",
    "# Get accuracy and codes for category 0\n",
    "accuracy0, codes0 = test_image_model(test_dir, 0)\n",
    "print('类别0的准确率:', accuracy0)\n",
    "print('类别0的测试结果:', codes0)\n",
    "\n",
    "# Get accuracy and codes for category 1\n",
    "accuracy1, codes1 = test_image_model(test_dir, 1)\n",
    "print('类别1的准确率:', accuracy1)\n",
    "print('类别1的测试结果:', codes1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6540dc2-c992-4bfa-992f-81cc63fc73ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
