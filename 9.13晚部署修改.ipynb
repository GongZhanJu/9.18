{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8ad25b6-f2d9-4134-9eda-7bef064c3aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "import pathlib\n",
    "import math\n",
    "import numpy as np\n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3be85b9-d2c0-4089-b97a-8edab8755322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "API_BASE_URL = 'http://fireeye-test-backend-container:9090/api/'\n",
    "TF_SERVING_BASE_URL = 'http://fireeye-test-model-container:8501/'\n",
    "task_id = '1ac1e8a095df4611af387d9934799251'\n",
    "id_code_mapping = {\n",
    "    'dbee3deebc5444f5b011da4e5518752c': '0',\n",
    "    'edb4cb51d54644c08aa122d3f041bb0a': '1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76012b3c-737d-4c1d-aa89-9ce2bc2387d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_by_id(image_id):\n",
    "    \"\"\"Retrieve image by its ID.\"\"\"\n",
    "    r = requests.get(url=API_BASE_URL + 'image/' + image_id)\n",
    "    if r.status_code == 200:\n",
    "        return Image.open(io.BytesIO(r.content))\n",
    "    else:\n",
    "        raise RuntimeError(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "815320be-3292-4d22-99a6-1a2a4ea21dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该类别下图片数量是：320\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "def get_image_records(task_id):\n",
    "    \"\"\"Fetch image records given a task ID.\"\"\"\n",
    "    resp = requests.get(\n",
    "        url=API_BASE_URL + 'image',\n",
    "        params={'task_id': task_id, 'has_truth': True}\n",
    "    )\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        raise RuntimeError(resp.text)\n",
    "image_records = get_image_records(task_id)\n",
    "print(f'该类别下图片数量是：{len(image_records)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b0c0ae-0a27-40a3-a0ae-cc4415576cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crop_by_percentile(img, lower_percentile=5, upper_percentile=95):\n",
    "    img_array = np.array(img.convert('L'))\n",
    "    \n",
    "    low_val, high_val = np.percentile(img_array, [lower_percentile,upper_percentile])\n",
    "                         \n",
    "    mask = np.logical_and(img_array > low_val, img_array < high_val)\n",
    "    rows = np.any(mask, axis=1)\n",
    "    cols = np.any(mask, axis=0)\n",
    "                         \n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    cropped_img = img.crop((cmin, rmin, cmax, rmax))\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c845b9a9-6bcc-4e30-a9ef-e4dccaae5f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image(img: Image.Image) -> np.ndarray:\n",
    "    img_array = np.array(img)\n",
    "    return img_array / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3d05648-952f-4c26-a4d9-8208438777d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_dir = \"./images\"\n",
    "Category0_dir = os.path.join(image_dir, 'Category0')\n",
    "Category1_dir = os.path.join(image_dir, 'Category1')\n",
    "if os.path.exists(Category0_dir):\n",
    "    shutil.rmtree(Category0_dir)\n",
    "if os.path.exists(Category1_dir):\n",
    "    shutil.rmtree(Category1_dir)\n",
    "\n",
    "\n",
    "os.makedirs(Category0_dir)\n",
    "os.makedirs(Category1_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca9430cc-693c-46cf-9266-2e75f30899c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clear_and_create_directory(directory):\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    os.makedirs(directory)\n",
    "\n",
    "base_dir = './images'    \n",
    "\n",
    "for set_name in ['train', 'test', 'val']:\n",
    "    for category in ['Category0', 'Category1']:\n",
    "        directory = os.path.join(base_dir, set_name, category)\n",
    "        clear_and_create_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb9eca4-2400-4c2d-ad85-82bbe86450f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [id_code_mapping[record['truth_id']] for record in image_records]\n",
    "\n",
    "\n",
    "train_records, test_records, train_labels, test_labels = train_test_split(\n",
    "    image_records, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "train_records, val_records, train_labels, val_labels = train_test_split(\n",
    "    train_records, train_labels, test_size=0.1, stratify=train_labels, random_state=42)\n",
    "\n",
    "\n",
    "for set_name, records in [('train', train_records), ('test', test_records), ('val', val_records)]:\n",
    "    for record in records:\n",
    "        try:\n",
    "            img = get_image_by_id(record['id'])\n",
    "            cropped_img = crop_by_percentile(img)\n",
    "            normalized_img_array = np.array(cropped_img) / 255.0\n",
    "            normalized_img = Image.fromarray((normalized_img_array * 255).astype(np.uint8))\n",
    "\n",
    "            truth_id = record['truth_id']\n",
    "            category = id_code_mapping[truth_id]\n",
    "            \n",
    "            directory = os.path.join(base_dir, set_name, f'Category{category}')\n",
    "            file_path = os.path.join(directory, f'{record[\"id\"]}.png')\n",
    "            normalized_img.save(file_path, 'PNG')\n",
    "        except Exception as e:\n",
    "            print(f'Error processing image {record[\"id\"]}. Error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63eaeddc-6cb4-43cf-929b-6b2e6eb7dfc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_image(image_id):\n",
    "    response = requests.get(f\"{API_BASE_URL}image/download/{image_id}\")\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "620373ff-f17f-4f80-9b27-071677d3a5f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def color_jitter(img: Image.Image, brightness=0.2, contrast=0.2, saturation=0.2) -> Image.Image:\n",
    "    img = ImageEnhance.Brightness(img).enhance(1 + brightness * (2 * np.random.random() - 1))\n",
    "    img = ImageEnhance.Contrast(img).enhance(1 + contrast * (2 * np.random.random() - 1))\n",
    "    img = ImageEnhance.Color(img).enhance(1 + saturation * (2 * np.random.random() - 1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d55601c5-7dab-4c51-8705-d1b8754423bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vertical_flip(img: Image.Image) -> Image.Image:\n",
    "    return ImageOps.flip(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f45fa63d-790e-4a4d-8957-38d0ee14f1ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def horizontal_flip(img: Image.Image) -> Image.Image:\n",
    "    return ImageOps.mirror(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d66fee42-d32f-4e2d-bbfd-a5315c458077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation for teh training set is complete.\n"
     ]
    }
   ],
   "source": [
    "train_directory = './images/train/'\n",
    "\n",
    "\n",
    "def preprocess_and_save(img, image_id, category):\n",
    "    color_jittered = color_jitter(img)\n",
    "    color_jittered_path = os.path.join(train_directory, category, f'{image_id}_colorjittered.png')\n",
    "    color_jittered.save(color_jittered_path, 'PNG')\n",
    "\n",
    "    vflipped = vertical_flip(img)\n",
    "    vflipped_path = os.path.join(train_directory, category, f'{image_id}_vflipped.png')\n",
    "    vflipped.save(vflipped_path, 'PNG')\n",
    "\n",
    "    hflipped = horizontal_flip(img)\n",
    "    hflipped_path = os.path.join(train_directory, category, f'{image_id}_hflipped.png')\n",
    "    hflipped.save(hflipped_path, 'PNG')\n",
    "\n",
    "for record in train_records:\n",
    "    image_id = record['id']\n",
    "    img = get_image_by_id(image_id)\n",
    "    truth_id = record['truth_id']\n",
    "    category = f'Category{id_code_mapping[truth_id]}'\n",
    "    preprocess_and_save(img, image_id, category)\n",
    "    \n",
    "print('Data augmentation for teh training set is complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8db4235c-440d-4ae4-9f34-dce7ee59dd05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "print(tf.__version__)\n",
    "train_dir = './images/train'\n",
    "val_dir = './images/val'\n",
    "test_dir = './images/test'\n",
    "\n",
    "img_height, img_width = 218, 175\n",
    "input_shape = (img_height, img_width, 3)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bcbe223-bedb-4bfa-8979-6a4f3977b99f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 804 images belonging to 2 classes.\n",
      "Found 23 images belonging to 2 classes.\n",
      "Found 96 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation and normalization for training\n",
    "train_image_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Just rescaling for validation and test\n",
    "val_image_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "test_image_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Data Loading\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(img_height, img_width),\n",
    "                                                           class_mode='binary')\n",
    "\n",
    "val_data_gen = val_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                       directory=val_dir,\n",
    "                                                       target_size=(img_height, img_width),\n",
    "                                                       class_mode='binary')\n",
    "\n",
    "test_data_gen = test_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                         directory=test_dir,\n",
    "                                                         target_size=(img_height, img_width),\n",
    "                                                         class_mode='binary')\n",
    "\n",
    "\n",
    "# 2. Model Creation and Compilation\n",
    "\n",
    "def create_advanced_cnn(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_advanced_cnn(input_shape)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d2c8f83-b503-4709-b116-2786f0c2063b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 12s 470ms/step - loss: 0.8756 - accuracy: 0.6101\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 12s 483ms/step - loss: 0.3256 - accuracy: 0.8863\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 12s 471ms/step - loss: 0.2242 - accuracy: 0.9197\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 12s 469ms/step - loss: 0.1977 - accuracy: 0.9249\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 12s 484ms/step - loss: 0.1564 - accuracy: 0.9378\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 12s 470ms/step - loss: 0.1613 - accuracy: 0.9404\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 12s 473ms/step - loss: 0.0887 - accuracy: 0.9702\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 12s 475ms/step - loss: 0.0538 - accuracy: 0.9780\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 12s 483ms/step - loss: 0.0235 - accuracy: 0.9935\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 12s 482ms/step - loss: 0.0148 - accuracy: 0.9961\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=train_data_gen.samples // BATCH_SIZE,\n",
    "    epochs=10,  # Adjust as needed\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=val_data_gen.samples // BATCH_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c10a3b8f-266b-4a53-905a-07f86236b2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 285ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Test accuracy: 1.0\n",
      "INFO:tensorflow:Assets written to: ./saved_model/my_model/assets\n",
      "Model saved to ./saved_model/my_model\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data_gen)\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "model_path = \"./saved_model/my_model\"\n",
    "model.save(model_path)\n",
    "print(\"Model saved to\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e78a4d78-3b89-4d99-882e-49e6d6ac01d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /models/slot1/20230913161840/assets\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "#model_version = datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y%m%d%H%M%S')\n",
    "#tf.keras.models.save_model(\n",
    "#    model,\n",
    "#    f'/models/slot1/{model_version}/',\n",
    "#    overwrite=True,\n",
    "#)\n",
    "model_version = datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y%m%d%H%M%S')\n",
    "model_save_path = f'/models/slot1/{model_version}/'\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    model_save_path,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59a1ca0a-0c04-40f7-a05d-8b1e9a1205c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Request tf-serving failed: <HTML><HEAD>\n<TITLE>404 Not Found</TITLE>\n</HEAD><BODY>\n<H1>Not Found</H1>\n</BODY></HTML>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42578/529334918.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0msingle_image_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Category0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msingle_image_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_42578/529334918.py\u001b[0m in \u001b[0;36mpredict_image\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Request tf-serving failed: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mresp_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Request tf-serving failed: <HTML><HEAD>\n<TITLE>404 Not Found</TITLE>\n</HEAD><BODY>\n<H1>Not Found</H1>\n</BODY></HTML>\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "\n",
    "TF_SERVING_BASE_URL = 'http://fireeye-test-model-container:8501/' \n",
    "\n",
    "\n",
    "def predict_image(images):\n",
    "    image_list = []\n",
    "\n",
    "    for image_path in images:\n",
    "        with open(image_path, 'rb') as fimage:\n",
    "            content = fimage.read()\n",
    "        b64_encoded_image = base64.urlsafe_b64encode(content).decode('utf-8')\n",
    "        image_list.append({\"b64\": b64_encoded_image})\n",
    "\n",
    "    # Format the payload\n",
    "    payload = {\n",
    "        \"signature_name\": \"serving_default\",\n",
    "        \"instances\": image_list\n",
    "    }\n",
    "\n",
    "    # Make the request\n",
    "    response = requests.post(TF_SERVING_BASE_URL,\n",
    "                             data=json.dumps(payload),\n",
    "                             headers={\"content-type\": \"application/json\"})\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError('Request tf-serving failed: ' + response.text)\n",
    "\n",
    "    resp_data = json.loads(response.text)\n",
    "    if 'outputs' not in resp_data or type(resp_data['outputs']) is not list:\n",
    "        raise RuntimeError('Invalid tf-serving response format: ' + response.text)\n",
    "\n",
    "    return resp_data['outputs']\n",
    "\n",
    "\n",
    "def test_image_model(test_dir, code, batch_size=10):\n",
    "    # Mapping the codes to their directory names\n",
    "    code_to_category = {\n",
    "        0: \"Category0\",\n",
    "        1: \"Category1\"\n",
    "    }\n",
    "\n",
    "    category_dir = code_to_category.get(code)\n",
    "    if category_dir is None:\n",
    "        raise ValueError(f\"Invalid code {code}. Expected 0 or 1.\")\n",
    "\n",
    "    code_dir = pathlib.Path(test_dir).joinpath(category_dir)\n",
    "\n",
    "    if not code_dir.exists():\n",
    "        raise FileNotFoundError(f\"The directory {code_dir} does not exist!\")\n",
    "\n",
    "    images = list(code_dir.glob('*.png'))\n",
    "    codes = []\n",
    "\n",
    "    total_images = len(images)\n",
    "    print(f\"Total images found in {category_dir}: {total_images}\")  # Debug: check the total number of images found\n",
    "\n",
    "    for step in range(math.ceil(total_images / batch_size)):\n",
    "        outputs = predict_image(images[step * batch_size:(step + 1) * batch_size])\n",
    "        for i, o in zip(images, outputs):\n",
    "            if o != code:\n",
    "                print('Error picture:', i)\n",
    "        codes.extend(outputs)\n",
    "\n",
    "    accuracy = round(codes.count(code) / len(codes), 4)\n",
    "    return accuracy, codes\n",
    "\n",
    "single_image_path = pathlib.Path(test_dir).joinpath('Category0').glob('*.png').__next__()\n",
    "response = predict_image([single_image_path])\n",
    "print(response)\n",
    "\n",
    "\n",
    "\n",
    "accuracy, codes = test_image_model(test_dir, 0)\n",
    "print('类别0的准确率:', accuracy)\n",
    "print('类别0的测试结果:', codes)\n",
    "\n",
    "accuracy, codes = test_image_model(test_dir, 1)\n",
    "print('类别1的准确率:', accuracy)\n",
    "print('类别1的测试结果:', codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6540dc2-c992-4bfa-992f-81cc63fc73ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
