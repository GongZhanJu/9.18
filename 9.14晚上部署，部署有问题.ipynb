{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ad25b6-f2d9-4134-9eda-7bef064c3aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "import pathlib\n",
    "import math\n",
    "import numpy as np\n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3be85b9-d2c0-4089-b97a-8edab8755322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "API_BASE_URL = 'http://fireeye-test-backend-container:9090/api/'\n",
    "TF_SERVING_BASE_URL = 'http://fireeye-test-model-container:8501/'\n",
    "task_id = '1ac1e8a095df4611af387d9934799251'\n",
    "id_code_mapping = {\n",
    "    'dbee3deebc5444f5b011da4e5518752c': '0',\n",
    "    'edb4cb51d54644c08aa122d3f041bb0a': '1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76012b3c-737d-4c1d-aa89-9ce2bc2387d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_by_id(image_id):\n",
    "    \"\"\"Retrieve image by its ID.\"\"\"\n",
    "    r = requests.get(url=API_BASE_URL + 'image/' + image_id)\n",
    "    if r.status_code == 200:\n",
    "        return Image.open(io.BytesIO(r.content))\n",
    "    else:\n",
    "        raise RuntimeError(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "815320be-3292-4d22-99a6-1a2a4ea21dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该类别下图片数量是：320\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "def get_image_records(task_id):\n",
    "    \"\"\"Fetch image records given a task ID.\"\"\"\n",
    "    resp = requests.get(\n",
    "        url=API_BASE_URL + 'image',\n",
    "        params={'task_id': task_id, 'has_truth': True}\n",
    "    )\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        raise RuntimeError(resp.text)\n",
    "image_records = get_image_records(task_id)\n",
    "print(f'该类别下图片数量是：{len(image_records)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b0c0ae-0a27-40a3-a0ae-cc4415576cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crop_by_percentile(img, lower_percentile=5, upper_percentile=95):\n",
    "    img_array = np.array(img.convert('L'))\n",
    "    \n",
    "    low_val, high_val = np.percentile(img_array, [lower_percentile,upper_percentile])\n",
    "                         \n",
    "    mask = np.logical_and(img_array > low_val, img_array < high_val)\n",
    "    rows = np.any(mask, axis=1)\n",
    "    cols = np.any(mask, axis=0)\n",
    "                         \n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    cropped_img = img.crop((cmin, rmin, cmax, rmax))\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c845b9a9-6bcc-4e30-a9ef-e4dccaae5f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image(img: Image.Image) -> np.ndarray:\n",
    "    img_array = np.array(img)\n",
    "    return img_array / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3d05648-952f-4c26-a4d9-8208438777d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_dir = \"./images\"\n",
    "Category0_dir = os.path.join(image_dir, 'Category0')\n",
    "Category1_dir = os.path.join(image_dir, 'Category1')\n",
    "if os.path.exists(Category0_dir):\n",
    "    shutil.rmtree(Category0_dir)\n",
    "if os.path.exists(Category1_dir):\n",
    "    shutil.rmtree(Category1_dir)\n",
    "\n",
    "\n",
    "os.makedirs(Category0_dir)\n",
    "os.makedirs(Category1_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca9430cc-693c-46cf-9266-2e75f30899c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clear_and_create_directory(directory):\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    os.makedirs(directory)\n",
    "\n",
    "base_dir = './images'\n",
    "\n",
    "for set_name in ['train', 'test', 'val']:\n",
    "    for category in ['Category0', 'Category1']:\n",
    "        directory = os.path.join(base_dir, set_name, category)\n",
    "        clear_and_create_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb9eca4-2400-4c2d-ad85-82bbe86450f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [id_code_mapping[record['truth_id']] for record in image_records]\n",
    "\n",
    "\n",
    "train_records, test_records, train_labels, test_labels = train_test_split(\n",
    "    image_records, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "train_records, val_records, train_labels, val_labels = train_test_split(\n",
    "    train_records, train_labels, test_size=0.1, stratify=train_labels, random_state=42)\n",
    "\n",
    "# Processing & Saving for Training Set\n",
    "for record in train_records:\n",
    "    try:\n",
    "        img = get_image_by_id(record['id'])\n",
    "        cropped_img = crop_by_percentile(img)\n",
    "        normalized_img_array = np.array(cropped_img) / 255.0\n",
    "        normalized_img = Image.fromarray((normalized_img_array * 255).astype(np.uint8))\n",
    "\n",
    "        truth_id = record['truth_id']\n",
    "        category = id_code_mapping[truth_id]\n",
    "\n",
    "        directory = os.path.join(base_dir, 'train', f'Category{category}')\n",
    "        file_path = os.path.join(directory, f'{record[\"id\"]}.png')\n",
    "        normalized_img.save(file_path, 'PNG')\n",
    "    except Exception as e:\n",
    "        print(f'Error processing image {record[\"id\"]}. Error: {e}')\n",
    "\n",
    "# Saving images for Test and Validation Sets without processing\n",
    "for set_name, records in [('test', test_records), ('val', val_records)]:\n",
    "    for record in records:\n",
    "        try:\n",
    "            img = get_image_by_id(record['id'])\n",
    "\n",
    "            truth_id = record['truth_id']\n",
    "            category = id_code_mapping[truth_id]\n",
    "\n",
    "            directory = os.path.join(base_dir, set_name, f'Category{category}')\n",
    "            file_path = os.path.join(directory, f'{record[\"id\"]}.png')\n",
    "            img.save(file_path, 'PNG')\n",
    "        except Exception as e:\n",
    "            print(f'Error saving image {record[\"id\"]}. Error: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63eaeddc-6cb4-43cf-929b-6b2e6eb7dfc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_image(image_id):\n",
    "    response = requests.get(f\"{API_BASE_URL}image/download/{image_id}\")\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "620373ff-f17f-4f80-9b27-071677d3a5f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def color_jitter(img: Image.Image, brightness=0.2, contrast=0.2, saturation=0.2) -> Image.Image:\n",
    "    img = ImageEnhance.Brightness(img).enhance(1 + brightness * (2 * np.random.random() - 1))\n",
    "    img = ImageEnhance.Contrast(img).enhance(1 + contrast * (2 * np.random.random() - 1))\n",
    "    img = ImageEnhance.Color(img).enhance(1 + saturation * (2 * np.random.random() - 1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d55601c5-7dab-4c51-8705-d1b8754423bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vertical_flip(img: Image.Image) -> Image.Image:\n",
    "    return ImageOps.flip(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f45fa63d-790e-4a4d-8957-38d0ee14f1ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def horizontal_flip(img: Image.Image) -> Image.Image:\n",
    "    return ImageOps.mirror(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d66fee42-d32f-4e2d-bbfd-a5315c458077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation for the training set is complete\n"
     ]
    }
   ],
   "source": [
    "train_directory = './images/train/'\n",
    "\n",
    "\n",
    "def preprocess_and_save(img_path, image_id, category):\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    color_jittered = color_jitter(img)\n",
    "    color_jittered_path = os.path.join(train_directory, category, f'{image_id}_colorjittered.png')\n",
    "    color_jittered.save(color_jittered_path, 'PNG')\n",
    "\n",
    "    vflipped = vertical_flip(img)\n",
    "    vflipped_path = os.path.join(train_directory, category, f'{image_id}_vflipped.png')\n",
    "    vflipped.save(vflipped_path, 'PNG')\n",
    "\n",
    "    hflipped = horizontal_flip(img)\n",
    "    hflipped_path = os.path.join(train_directory, category, f'{image_id}_hflipped.png')\n",
    "    hflipped.save(hflipped_path, 'PNG')\n",
    "#    img = get_image_by_id(image_id)\n",
    "for record in train_records:\n",
    "    image_id = record['id']\n",
    "    truth_id = record['truth_id']\n",
    "    category = f'Category{id_code_mapping[truth_id]}'\n",
    "    img_path = os.path.join(train_directory, category, f'{image_id}.png')\n",
    "    if os.path.exists(img_path):\n",
    "        preprocess_and_save(img_path, image_id, category)\n",
    "print('Data augmentation for the training set is complete')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db4235c-440d-4ae4-9f34-dce7ee59dd05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "print(tf.__version__)\n",
    "train_dir = './images/train'\n",
    "val_dir = './images/val'\n",
    "test_dir = './images/test'\n",
    "\n",
    "img_height, img_width = 218, 175\n",
    "input_shape = (img_height, img_width, 3)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bcbe223-bedb-4bfa-8979-6a4f3977b99f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 804 images belonging to 2 classes.\n",
      "Found 23 images belonging to 3 classes.\n",
      "Found 96 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 13:15:10.687522: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-09-14 13:15:10.687677: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-09-14 13:15:10.687742: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (58c881efe57c): /proc/driver/nvidia/version does not exist\n",
      "2023-09-14 13:15:10.688411: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "val_image_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "test_image_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(img_height, img_width),\n",
    "                                                           class_mode='binary')\n",
    "\n",
    "val_data_gen = val_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                       directory=val_dir,\n",
    "                                                       target_size=(img_height, img_width),\n",
    "                                                       class_mode='binary')\n",
    "\n",
    "test_data_gen = test_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                         directory=test_dir,\n",
    "                                                         target_size=(img_height, img_width),\n",
    "                                                         class_mode='binary')\n",
    "\n",
    "\n",
    "def create_advanced_cnn(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_advanced_cnn(input_shape)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d2c8f83-b503-4709-b116-2786f0c2063b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 [==============================] - 13s 465ms/step - loss: 0.8447 - accuracy: 0.6801\n",
      "Epoch 2/30\n",
      "25/25 [==============================] - 12s 468ms/step - loss: 0.2039 - accuracy: 0.9288\n",
      "Epoch 3/30\n",
      "25/25 [==============================] - 12s 466ms/step - loss: 0.2105 - accuracy: 0.9223\n",
      "Epoch 4/30\n",
      "25/25 [==============================] - 12s 469ms/step - loss: 0.1164 - accuracy: 0.9585\n",
      "Epoch 5/30\n",
      "25/25 [==============================] - 12s 469ms/step - loss: 0.0664 - accuracy: 0.9741\n",
      "Epoch 6/30\n",
      "25/25 [==============================] - 12s 468ms/step - loss: 0.0400 - accuracy: 0.9858\n",
      "Epoch 7/30\n",
      "25/25 [==============================] - 12s 469ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "25/25 [==============================] - 12s 471ms/step - loss: 0.0149 - accuracy: 0.9935\n",
      "Epoch 9/30\n",
      "25/25 [==============================] - 12s 470ms/step - loss: 0.0133 - accuracy: 0.9974\n",
      "Epoch 10/30\n",
      "25/25 [==============================] - 12s 469ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "25/25 [==============================] - 12s 469ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "25/25 [==============================] - 12s 471ms/step - loss: 0.0034 - accuracy: 0.9987\n",
      "Epoch 13/30\n",
      "25/25 [==============================] - 12s 469ms/step - loss: 0.0025 - accuracy: 0.9987\n",
      "Epoch 14/30\n",
      "25/25 [==============================] - 12s 472ms/step - loss: 7.7966e-04 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "25/25 [==============================] - 12s 472ms/step - loss: 7.7662e-04 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "25/25 [==============================] - 12s 470ms/step - loss: 0.0196 - accuracy: 0.9922\n",
      "Epoch 17/30\n",
      "25/25 [==============================] - 12s 475ms/step - loss: 0.0057 - accuracy: 0.9987\n",
      "Epoch 18/30\n",
      "25/25 [==============================] - 12s 478ms/step - loss: 6.2777e-04 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "25/25 [==============================] - 12s 487ms/step - loss: 6.2499e-04 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "25/25 [==============================] - 12s 484ms/step - loss: 4.1928e-04 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "25/25 [==============================] - 12s 479ms/step - loss: 0.0079 - accuracy: 0.9948\n",
      "Epoch 22/30\n",
      "25/25 [==============================] - 12s 479ms/step - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 23/30\n",
      "25/25 [==============================] - 12s 477ms/step - loss: 0.0159 - accuracy: 0.9948\n",
      "Epoch 24/30\n",
      "25/25 [==============================] - 12s 473ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "25/25 [==============================] - 12s 472ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "25/25 [==============================] - 12s 471ms/step - loss: 7.7166e-04 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "25/25 [==============================] - 12s 472ms/step - loss: 5.8186e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "25/25 [==============================] - 12s 471ms/step - loss: 6.1034e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "25/25 [==============================] - 12s 471ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "25/25 [==============================] - 12s 474ms/step - loss: 3.7161e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=train_data_gen.samples // BATCH_SIZE,\n",
    "    epochs=30,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=val_data_gen.samples // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c10a3b8f-266b-4a53-905a-07f86236b2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 245ms/step - loss: -9.4082 - accuracy: 0.0208\n",
      "Test accuracy: 0.02083333395421505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 13:21:12.470590: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/my_model/assets\n",
      "Model saved to ./saved_model/my_model\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data_gen)\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "model_path = \"./saved_model/my_model\"\n",
    "model.save(model_path)\n",
    "print(\"Model saved to\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e78a4d78-3b89-4d99-882e-49e6d6ac01d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /models/slot1/20230914212115/assets\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "#model_version = datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y%m%d%H%M%S')\n",
    "#tf.keras.models.save_model(\n",
    "#    model,\n",
    "#    f'/models/slot1/{model_version}/',\n",
    "#    overwrite=True,\n",
    "#)\n",
    "model_version = datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y%m%d%H%M%S')\n",
    "model_save_path = f'/models/slot1/{model_version}/'\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    model_save_path,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3dbff37c-105c-41a6-ae7f-b89c88d70c70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "错误图片： images/val/0/da1d0143e7b44fe2b4a2aca4fce84596.png\n",
      "错误图片： images/val/0/3ee77106d5aa4c91bf7345f4e5ef2710.png\n",
      "错误图片： images/val/0/678702d785014e0c910936788eb4fedb.png\n",
      "错误图片： images/val/0/a3a340fba4b2485aa2e0b2df5c55c4f5.png\n",
      "错误图片： images/val/0/7d835a4839514528b17fa8987798677d.png\n",
      "错误图片： images/val/0/83ec5a739dc74a4ba49e47ce6c0c05c3.png\n",
      "错误图片： images/val/0/a9ba916a09b04e5a81ab481f87050f6b.png\n",
      "错误图片： images/val/0/32faa419eb9a4bc2a0c3bab3fcda05d0.png\n",
      "错误图片： images/val/0/dfcee39e-f12b-4fb4-ae00-b9be0ce3645e.png\n",
      "错误图片： images/val/0/88a5285013ee4cdf99a873bd02a9f0fa.png\n",
      "错误图片： images/val/0/da1d0143e7b44fe2b4a2aca4fce84596.png\n",
      "错误图片： images/val/0/3ee77106d5aa4c91bf7345f4e5ef2710.png\n",
      "类别0的准确率 0.0\n",
      "类别0的测试结果 [[0.000460088253], [0.000924885273], [8.27497424e-05], [0.000131964684], [0.000201255083], [0.000637829304], [6.66303e-05], [1.50187143e-05], [8.33176273e-06], [0.000162571669], [0.000171154737], [0.000151693821]]\n",
      "错误图片： images/val/1/1b57445bce424a2a825417625bc91a67.png\n",
      "错误图片： images/val/1/c95d3ccf5b114cc8b7d3c7c30a9b8e8c.png\n",
      "错误图片： images/val/1/a4b68a4136f948b8a944960beacb10a9.png\n",
      "错误图片： images/val/1/cba4c61b17e1454288859813fa0bbfa7.png\n",
      "错误图片： images/val/1/21577c1e1d4b47f5af4fbcbb19f2ebce.png\n",
      "错误图片： images/val/1/4027c70db6314b68b3f7ae14426fe575.png\n",
      "错误图片： images/val/1/1fa7908f-075a-4150-aea7-b97da0fcf8c4.png\n",
      "错误图片： images/val/1/a6708936-64aa-43e1-9188-ea15495ac7d8.png\n",
      "错误图片： images/val/1/ee73ea284f574c51b6d8b359c4b6c791.png\n",
      "错误图片： images/val/1/72c5460200e2470092421bbc7890690a.png\n",
      "错误图片： images/val/1/1b57445bce424a2a825417625bc91a67.png\n",
      "类别1的准确率 0.0\n",
      "类别1的测试结果 [[0.000207662582], [0.00237330794], [2.73718433e-05], [3.88670378e-05], [0.489750504], [0.0152497888], [0.0109896064], [4.38106326e-05], [0.000126481056], [0.000908106565], [8.17029616e-07]]\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "import PIL\n",
    "import PIL.Image as PImage\n",
    "from PIL import ImageEnhance\n",
    "import math\n",
    "from pprint import pprint\n",
    "import glob\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def image_to_tf_format(img: Image.Image) -> List[List[List[float]]]:\n",
    "    img = img.resize((218, 175)).convert('RGB')\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array.tolist()\n",
    "    \n",
    "\n",
    "\n",
    "def predict_image(images: List[Image.Image]):\n",
    "    data = [image_to_tf_format(img) for img in images]\n",
    "\n",
    "    json_data ={\n",
    "      'signature_name': 'serving_default',\n",
    "      'instances': data\n",
    "    }\n",
    "    response = requests.post(url=TF_SERVING_BASE_URL+f'v1/models/slot1/versions/{model_version}:predict', # 根据部署地址填写\n",
    "                             json=json_data,\n",
    "                             headers={\"content-type\": \"application/json\"})\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError('Request tf-serving failed: ' + response.text)\n",
    "    resp_data = json.loads(response.text)    \n",
    "    if 'predictions' not in resp_data:\n",
    "        print(f'Unexpected response form TensorFlow Serving: {resp_data}')\n",
    "        raise RuntimeError('Invalid response from TensorFlow Serving')\n",
    "    return resp_data['predictions']\n",
    "\n",
    "\n",
    "def test_image_model(test_dir, code, batch_size=10):    \n",
    "    image_paths = list(pathlib.Path(test_dir).joinpath(str(code)).glob('./*.png')) \n",
    "    \n",
    "    images = [Image.open(img_path) for img_path in image_paths]\n",
    "    codes = []\n",
    "    for step in range(math.ceil(len(images)/batch_size)):\n",
    "        outputs = predict_image(images[step*batch_size:(step+1)*batch_size])\n",
    "        for i, o in zip(image_paths, outputs):            \n",
    "            if o != code:\n",
    "                print('错误图片：', i)\n",
    "        codes.extend(outputs)\n",
    "    accuracy = round(codes.count(code) / len(codes), 4)\n",
    "    return accuracy, codes\n",
    "\n",
    "accuracy, codes = test_image_model(val_dir, 0)\n",
    "print('类别0的准确率', accuracy)\n",
    "print('类别0的测试结果', codes)\n",
    "accuracy, codes = test_image_model(val_dir, 1)\n",
    "print('类别1的准确率', accuracy)\n",
    "print('类别1的测试结果', codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced222ec-b40d-413e-9ddd-73b7863af29c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
