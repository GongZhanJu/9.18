{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8ad25b6-f2d9-4134-9eda-7bef064c3aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "import pathlib\n",
    "import math\n",
    "import numpy as np\n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3be85b9-d2c0-4089-b97a-8edab8755322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "API_BASE_URL = 'http://fireeye-test-backend-container:9090/api/'\n",
    "TF_SERVING_BASE_URL = 'http://fireeye-test-model-container:8501/'\n",
    "task_id = '1ac1e8a095df4611af387d9934799251'\n",
    "id_code_mapping = {\n",
    "    'dbee3deebc5444f5b011da4e5518752c': '0',\n",
    "    'edb4cb51d54644c08aa122d3f041bb0a': '1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76012b3c-737d-4c1d-aa89-9ce2bc2387d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_by_id(image_id):\n",
    "    \"\"\"Retrieve image by its ID.\"\"\"\n",
    "    r = requests.get(url=API_BASE_URL + 'image/' + image_id)\n",
    "    if r.status_code == 200:\n",
    "        return Image.open(io.BytesIO(r.content))\n",
    "    else:\n",
    "        raise RuntimeError(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "815320be-3292-4d22-99a6-1a2a4ea21dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该类别下图片数量是：318\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "def get_image_records(task_id):\n",
    "    \"\"\"Fetch image records given a task ID.\"\"\"\n",
    "    resp = requests.get(\n",
    "        url=API_BASE_URL + 'image',\n",
    "        params={'task_id': task_id, 'has_truth': True}\n",
    "    )\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        raise RuntimeError(resp.text)\n",
    "image_records = get_image_records(task_id)\n",
    "print(f'该类别下图片数量是：{len(image_records)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9b0c0ae-0a27-40a3-a0ae-cc4415576cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crop_by_percentile(img, lower_percentile=5, upper_percentile=95):\n",
    "    img_array = np.array(img.convert('L'))\n",
    "    \n",
    "    low_val, high_val = np.percentile(img_array, [lower_percentile,upper_percentile])\n",
    "                         \n",
    "    mask = np.logical_and(img_array > low_val, img_array < high_val)\n",
    "    rows = np.any(mask, axis=1)\n",
    "    cols = np.any(mask, axis=0)\n",
    "                         \n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    cropped_img = img.crop((cmin, rmin, cmax, rmax))\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c845b9a9-6bcc-4e30-a9ef-e4dccaae5f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image(img: Image.Image) -> np.ndarray:\n",
    "    img_array = np.array(img)\n",
    "    return img_array / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3d05648-952f-4c26-a4d9-8208438777d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_dir = \"./images\"\n",
    "Category0_dir = os.path.join(image_dir, 'Category0')\n",
    "Category1_dir = os.path.join(image_dir, 'Category1')\n",
    "if os.path.exists(Category0_dir):\n",
    "    shutil.rmtree(Category0_dir)\n",
    "if os.path.exists(Category1_dir):\n",
    "    shutil.rmtree(Category1_dir)\n",
    "\n",
    "\n",
    "os.makedirs(Category0_dir)\n",
    "os.makedirs(Category1_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca9430cc-693c-46cf-9266-2e75f30899c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clear_and_create_directory(directory):\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    os.makedirs(directory)\n",
    "\n",
    "base_dir = './images'\n",
    "\n",
    "for set_name in ['train', 'test', 'val']:\n",
    "    for category in ['Category0', 'Category1']:\n",
    "        directory = os.path.join(base_dir, set_name, category)\n",
    "        clear_and_create_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9cb9eca4-2400-4c2d-ad85-82bbe86450f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [id_code_mapping[record['truth_id']] for record in image_records]\n",
    "\n",
    "\n",
    "train_records, test_records, train_labels, test_labels = train_test_split(\n",
    "    image_records, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "train_records, val_records, train_labels, val_labels = train_test_split(\n",
    "    train_records, train_labels, test_size=0.1, stratify=train_labels, random_state=42)\n",
    "\n",
    "\n",
    "for set_name, records in [('train', train_records), ('test', test_records), ('val', val_records)]:\n",
    "    for record in records:\n",
    "        try:\n",
    "            img = get_image_by_id(record['id'])\n",
    "            cropped_img = crop_by_percentile(img)\n",
    "            normalized_img_array = np.array(cropped_img) / 255.0\n",
    "            normalized_img = Image.fromarray((normalized_img_array * 255).astype(np.uint8))\n",
    "\n",
    "            truth_id = record['truth_id']\n",
    "            category = id_code_mapping[truth_id]\n",
    "\n",
    "            directory = os.path.join(base_dir, set_name, f'Category{category}')\n",
    "            file_path = os.path.join(directory, f'{record[\"id\"]}.png')\n",
    "            normalized_img.save(file_path, 'PNG')\n",
    "        except Exception as e:\n",
    "            print(f'Error processing image {record[\"id\"]}. Error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63eaeddc-6cb4-43cf-929b-6b2e6eb7dfc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_image(image_id):\n",
    "    response = requests.get(f\"{API_BASE_URL}image/download/{image_id}\")\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "620373ff-f17f-4f80-9b27-071677d3a5f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def color_jitter(img: Image.Image, brightness=0.2, contrast=0.2, saturation=0.2) -> Image.Image:\n",
    "    img = ImageEnhance.Brightness(img).enhance(1 + brightness * (2 * np.random.random() - 1))\n",
    "    img = ImageEnhance.Contrast(img).enhance(1 + contrast * (2 * np.random.random() - 1))\n",
    "    img = ImageEnhance.Color(img).enhance(1 + saturation * (2 * np.random.random() - 1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d55601c5-7dab-4c51-8705-d1b8754423bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vertical_flip(img: Image.Image) -> Image.Image:\n",
    "    return ImageOps.flip(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f45fa63d-790e-4a4d-8957-38d0ee14f1ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def horizontal_flip(img: Image.Image) -> Image.Image:\n",
    "    return ImageOps.mirror(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d66fee42-d32f-4e2d-bbfd-a5315c458077",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = './images/train/'\n",
    "\n",
    "\n",
    "def preprocess_and_save(img, image_id, category):\n",
    "    color_jittered = color_jitter(img)\n",
    "    color_jittered_path = os.path.join(train_directory, category, f'{image_id}_colorjittered.png')\n",
    "    color_jittered.save(color_jittered_path, 'PNG')\n",
    "\n",
    "    vflipped = vertical_flip(img)\n",
    "    vflipped_path = os.path.join(train_directory, category, f'{image_id}_vflipped.png')\n",
    "    vflipped.save(vflipped_path, 'PNG')\n",
    "\n",
    "    hflipped = horizontal_flip(img)\n",
    "    hflipped_path = os.path.join(train_directory, category, f'{image_id}_hflipped.png')\n",
    "    hflipped.save(hflipped_path, 'PNG')\n",
    "\n",
    "for record in train_records:\n",
    "    image_id = record['id']\n",
    "    img = get_image_by_id(image_id)\n",
    "    truth_id = record['truth_id']\n",
    "    category = f'Category{id_code_mapping[truth_id]}'\n",
    "    preprocess_and_save(img, image_id, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8db4235c-440d-4ae4-9f34-dce7ee59dd05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "print(tf.__version__)\n",
    "train_dir = './images/train'\n",
    "val_dir = './images/val'\n",
    "test_dir = './images/test'\n",
    "\n",
    "img_height, img_width = 218, 175\n",
    "input_shape = (img_height, img_width, 3)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bcbe223-bedb-4bfa-8979-6a4f3977b99f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 796 images belonging to 2 classes.\n",
      "Found 23 images belonging to 2 classes.\n",
      "Found 110 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 02:21:08.012080: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-09-14 02:21:08.012119: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-09-14 02:21:08.012135: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (58c881efe57c): /proc/driver/nvidia/version does not exist\n",
      "2023-09-14 02:21:08.012373: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "val_image_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "test_image_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(img_height, img_width),\n",
    "                                                           class_mode='binary')\n",
    "\n",
    "val_data_gen = val_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                       directory=val_dir,\n",
    "                                                       target_size=(img_height, img_width),\n",
    "                                                       class_mode='binary')\n",
    "\n",
    "test_data_gen = test_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                         directory=test_dir,\n",
    "                                                         target_size=(img_height, img_width),\n",
    "                                                         class_mode='binary')\n",
    "\n",
    "\n",
    "def create_advanced_cnn(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_advanced_cnn(input_shape)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d2c8f83-b503-4709-b116-2786f0c2063b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "24/24 [==============================] - 13s 495ms/step - loss: 0.5730 - accuracy: 0.7709\n",
      "Epoch 2/30\n",
      "24/24 [==============================] - 13s 541ms/step - loss: 0.2068 - accuracy: 0.9332\n",
      "Epoch 3/30\n",
      "24/24 [==============================] - 12s 510ms/step - loss: 0.1337 - accuracy: 0.9490\n",
      "Epoch 4/30\n",
      "24/24 [==============================] - 12s 491ms/step - loss: 0.1152 - accuracy: 0.9594\n",
      "Epoch 5/30\n",
      "24/24 [==============================] - 12s 488ms/step - loss: 0.0735 - accuracy: 0.9751\n",
      "Epoch 6/30\n",
      "24/24 [==============================] - 12s 488ms/step - loss: 0.0393 - accuracy: 0.9882\n",
      "Epoch 7/30\n",
      "24/24 [==============================] - 12s 487ms/step - loss: 0.0612 - accuracy: 0.9830\n",
      "Epoch 8/30\n",
      "24/24 [==============================] - 12s 489ms/step - loss: 0.0722 - accuracy: 0.9764\n",
      "Epoch 9/30\n",
      "24/24 [==============================] - 12s 489ms/step - loss: 0.0196 - accuracy: 0.9921\n",
      "Epoch 10/30\n",
      "24/24 [==============================] - 12s 492ms/step - loss: 0.0160 - accuracy: 0.9948\n",
      "Epoch 11/30\n",
      "24/24 [==============================] - 12s 501ms/step - loss: 0.0075 - accuracy: 0.9974\n",
      "Epoch 12/30\n",
      "24/24 [==============================] - 12s 500ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "24/24 [==============================] - 12s 498ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "24/24 [==============================] - 12s 499ms/step - loss: 7.6119e-04 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "24/24 [==============================] - 12s 500ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "24/24 [==============================] - 12s 493ms/step - loss: 5.6528e-04 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "24/24 [==============================] - 12s 492ms/step - loss: 5.4322e-04 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "24/24 [==============================] - 12s 491ms/step - loss: 2.6858e-04 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "24/24 [==============================] - 12s 490ms/step - loss: 4.8389e-04 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "24/24 [==============================] - 12s 495ms/step - loss: 7.6469e-04 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "24/24 [==============================] - 12s 495ms/step - loss: 1.2170e-04 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "24/24 [==============================] - 12s 493ms/step - loss: 1.1075e-04 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "24/24 [==============================] - 12s 492ms/step - loss: 4.0079e-04 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "24/24 [==============================] - 12s 493ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "24/24 [==============================] - 12s 490ms/step - loss: 4.0713e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "24/24 [==============================] - 12s 492ms/step - loss: 1.2410e-04 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "24/24 [==============================] - 12s 488ms/step - loss: 8.2341e-05 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "24/24 [==============================] - 12s 491ms/step - loss: 5.3272e-05 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "24/24 [==============================] - 12s 499ms/step - loss: 4.3435e-05 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "24/24 [==============================] - 12s 492ms/step - loss: 8.6747e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=train_data_gen.samples // BATCH_SIZE,\n",
    "    epochs=30,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=val_data_gen.samples // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c10a3b8f-266b-4a53-905a-07f86236b2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 165ms/step - loss: -18.3598 - accuracy: 0.0091\n",
      "Test accuracy: 0.00909090880304575\n",
      "INFO:tensorflow:Assets written to: ./saved_model/my_model/assets\n",
      "Model saved to ./saved_model/my_model\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data_gen)\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "model_path = \"./saved_model/my_model\"\n",
    "model.save(model_path)\n",
    "print(\"Model saved to\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e78a4d78-3b89-4d99-882e-49e6d6ac01d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /models/slot1/20230914102913/assets\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "#model_version = datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y%m%d%H%M%S')\n",
    "#tf.keras.models.save_model(\n",
    "#    model,\n",
    "#    f'/models/slot1/{model_version}/',\n",
    "#    overwrite=True,\n",
    "#)\n",
    "model_version = datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y%m%d%H%M%S')\n",
    "model_save_path = f'/models/slot1/{model_version}/'\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    model_save_path,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3dbff37c-105c-41a6-ae7f-b89c88d70c70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonono\n",
      "类别0的准确率 0\n",
      "类别0的测试结果 []\n",
      "nonono\n",
      "类别1的准确率 0\n",
      "类别1的测试结果 []\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "import PIL\n",
    "import PIL.Image as PImage\n",
    "from PIL import ImageEnhance\n",
    "import math\n",
    "from pprint import pprint\n",
    "import glob\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "def predict_image(images):\n",
    "    bimages = []\n",
    "    for image in images:\n",
    "        with open(image, 'rb') as fimage:\n",
    "            content = fimage.read()\n",
    "        bimage = base64.urlsafe_b64encode(content).decode()\n",
    "        bimages.append(bimage)\n",
    "    req_data ={\n",
    "      'inputs': bimages,\n",
    "    }\n",
    "    response = requests.post(TF_SERVING_BASE_URL+f'v1/models/slot1/versions/{model_version}:predict', # 根据部署地址填写\n",
    "                             json=req_data,\n",
    "                             headers={\"content-type\": \"application/json\"})\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError('Request tf-serving failed: ' + response.text)\n",
    "    resp_data = json.loads(response.text)    \n",
    "    if 'outputs' not in resp_data \\\n",
    "                        or type(resp_data['outputs']) is not list:\n",
    "        raise ValueError('Malformed tf-serving response')\n",
    "    outputs = np.argmax(resp_data['outputs'], axis=1).tolist()\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def test_image_model(test_dir, code, batch_size=10):    \n",
    "    images = list(pathlib.Path(test_dir).joinpath(str(code)).glob('./*.png')) \n",
    "    codes = []\n",
    "    for step in range(math.ceil(len(images)/batch_size)):\n",
    "        outputs = predict_image(images[step*batch_size:(step+1)*batch_size])\n",
    "        for i, o in zip(images, outputs):            \n",
    "            if o != code:\n",
    "                print('错误图片：', i)\n",
    "        codes.extend(outputs)\n",
    "    try:\n",
    "        accuracy = round(codes.count(code) / len(codes), 4)\n",
    "    except ZeroDivisionError:\n",
    "        print('No codes avai')\n",
    "        accuracy = 0\n",
    "    return accuracy, codes\n",
    "\n",
    "accuracy, codes = test_image_model(test_dir, 0)\n",
    "print('类别0的准确率', accuracy)\n",
    "print('类别0的测试结果', codes)\n",
    "accuracy, codes = test_image_model(test_dir, 1)\n",
    "print('类别1的准确率', accuracy)\n",
    "print('类别1的测试结果', codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced222ec-b40d-413e-9ddd-73b7863af29c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
